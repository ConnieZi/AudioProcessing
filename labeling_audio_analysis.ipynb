{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jab464/miniconda3/envs/pyannote/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/jab464/miniconda3/envs/pyannote/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowExxb\n",
      "  Referenced from: /Users/jab464/miniconda3/envs/pyannote/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in: /Users/jab464/miniconda3/envs/pyannote/lib/python3.8/site-packages/torch/lib/libc10.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import parselmouth\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "#import set of functions I made for the automatic analysis of the audios\n",
    "import sys\n",
    "\n",
    "#here the path needs to be changed to your own local path\n",
    "sys.path.insert(1, '/Users/jab464/Documents/Github/EMBRACE-data-analysis/')\n",
    "from audio_analysis_functions import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../EMBRACE-data-analysis/audios/record-667269360.9571331.wav'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m filename\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../EMBRACE-data-analysis/audios/record-667269360.9571331.wav\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#Classify small chunks into the identity of the speaker\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m audio \u001B[38;5;241m=\u001B[39m \u001B[43mAudioSegment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_wav\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m voice_activity \u001B[38;5;241m=\u001B[39m get_voice_activity(filename,\u001B[38;5;28;01mFalse\u001B[39;00m,\u001B[38;5;28;01mFalse\u001B[39;00m,\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      8\u001B[0m custom_size_voice_activity \u001B[38;5;241m=\u001B[39m custom_size_segments(voice_activity)\n",
      "File \u001B[0;32m~/miniconda3/envs/pyannote/lib/python3.8/site-packages/pydub/audio_segment.py:808\u001B[0m, in \u001B[0;36mAudioSegment.from_wav\u001B[0;34m(cls, file, parameters)\u001B[0m\n\u001B[1;32m    806\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    807\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_wav\u001B[39m(\u001B[38;5;28mcls\u001B[39m, file, parameters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 808\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwav\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/pyannote/lib/python3.8/site-packages/pydub/audio_segment.py:651\u001B[0m, in \u001B[0;36mAudioSegment.from_file\u001B[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001B[0m\n\u001B[1;32m    649\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    650\u001B[0m     filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 651\u001B[0m file, close_file \u001B[38;5;241m=\u001B[39m \u001B[43m_fd_or_path_or_tempfile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtempfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    653\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mformat\u001B[39m:\n\u001B[1;32m    654\u001B[0m     \u001B[38;5;28mformat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m.\u001B[39mlower()\n",
      "File \u001B[0;32m~/miniconda3/envs/pyannote/lib/python3.8/site-packages/pydub/utils.py:60\u001B[0m, in \u001B[0;36m_fd_or_path_or_tempfile\u001B[0;34m(fd, mode, tempfile)\u001B[0m\n\u001B[1;32m     57\u001B[0m     close_fd \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fd, basestring):\n\u001B[0;32m---> 60\u001B[0m     fd \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m     close_fd \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../EMBRACE-data-analysis/audios/record-667269360.9571331.wav'"
     ]
    }
   ],
   "source": [
    "#Audio dad-child (Pittsburgh)\n",
    "filename='../EMBRACE-data-analysis/audios/record-667269360.9571331.wav'\n",
    "\n",
    "#Classify small chunks into the identity of the speaker\n",
    "audio = AudioSegment.from_wav(filename)\n",
    "\n",
    "voice_activity = get_voice_activity(filename,False,False,False)\n",
    "custom_size_voice_activity = custom_size_segments(voice_activity)\n",
    "\n",
    "#manual labeling of the voice segments\n",
    "#child=c\n",
    "#robot male english = rme\n",
    "#robot male spanish = rms\n",
    "#robot female english = rfe\n",
    "#robot female spanish = rfs\n",
    "#adult male = am\n",
    "#adult female = af\n",
    "#(if additional adults number them)\n",
    "#adult male 2 = am2\n",
    "#adult female 2 = af2 ...\n",
    "#if they are talking simultaneously = A&B\n",
    "#if they are talking separately but sequentially = A,B\n",
    "\n",
    "labeling_file_str = \"\"\n",
    "starting_index = int(input(\"Which index would you like to start from? (type 0 if from the beginning or >0 if you want to continue labeling):\"))\n",
    "for i in range (starting_index,len(custom_size_voice_activity)):\n",
    "    active_segment = custom_size_voice_activity[i]\n",
    "#for active_segment in custom_size_voice_activity:\n",
    "    play_audio_segment(audio,active_segment[0]*1000,active_segment[1]*1000)\n",
    "    label = input(\"Enter label for this audio segment: \")\n",
    "    if(label==\"end\"):#stop tagging\n",
    "        break\n",
    "    while(label==\"r\"):#if you want the audio chunk to be repeated\n",
    "        play_audio_segment(audio,active_segment[0]*1000,active_segment[1]*1000)\n",
    "        label = input(\"Enter label for this audio segment: \")\n",
    "        if(label==\"end\"):\n",
    "            break\n",
    "    label_line = str(i)+\" \"+str(active_segment)+\" \"+label\n",
    "    labeling_file_str = labeling_file_str + label_line + \"\\n\"\n",
    "    print(str(i)+\" out of \"+str(len(custom_size_voice_activity)-1))\n",
    "if(starting_index==0):\n",
    "    f = open(filename+\"_labeled.txt\", \"w\")\n",
    "    f.write(labeling_file_str)\n",
    "    f.close()\n",
    "elif(starting_index<len(custom_size_voice_activity)):\n",
    "    f = open(filename+\"_labeled.txt\", \"a\")\n",
    "    f.write(labeling_file_str)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
