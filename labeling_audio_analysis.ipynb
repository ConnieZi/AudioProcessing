{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "#import set of functions I made for the automatic analysis of the audios\n",
    "import sys\n",
    "\n",
    "#here the path needs to be changed to your own local path\n",
    "sys.path.insert(1, '/Users/jab464/Documents/Github/EMBRACE-data-analysis/')\n",
    "from audio_analysis_functions import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total custom-size segments: 166\n",
      "0 out of 165\n",
      "1 out of 165\n",
      "2 out of 165\n",
      "3 out of 165\n",
      "4 out of 165\n",
      "5 out of 165\n",
      "6 out of 165\n",
      "7 out of 165\n",
      "8 out of 165\n",
      "9 out of 165\n",
      "10 out of 165\n",
      "11 out of 165\n",
      "12 out of 165\n",
      "13 out of 165\n",
      "14 out of 165\n",
      "15 out of 165\n",
      "16 out of 165\n",
      "17 out of 165\n",
      "18 out of 165\n",
      "19 out of 165\n",
      "20 out of 165\n",
      "21 out of 165\n",
      "22 out of 165\n",
      "23 out of 165\n",
      "24 out of 165\n",
      "25 out of 165\n",
      "26 out of 165\n",
      "27 out of 165\n",
      "28 out of 165\n",
      "29 out of 165\n",
      "30 out of 165\n",
      "31 out of 165\n",
      "32 out of 165\n",
      "33 out of 165\n",
      "34 out of 165\n",
      "35 out of 165\n",
      "36 out of 165\n",
      "37 out of 165\n",
      "38 out of 165\n",
      "39 out of 165\n",
      "40 out of 165\n",
      "41 out of 165\n",
      "42 out of 165\n",
      "43 out of 165\n",
      "44 out of 165\n",
      "45 out of 165\n",
      "46 out of 165\n",
      "47 out of 165\n",
      "48 out of 165\n",
      "49 out of 165\n",
      "50 out of 165\n",
      "51 out of 165\n",
      "52 out of 165\n",
      "53 out of 165\n",
      "54 out of 165\n",
      "55 out of 165\n",
      "56 out of 165\n",
      "57 out of 165\n",
      "58 out of 165\n",
      "59 out of 165\n",
      "60 out of 165\n",
      "61 out of 165\n",
      "62 out of 165\n",
      "63 out of 165\n",
      "64 out of 165\n",
      "65 out of 165\n",
      "66 out of 165\n",
      "67 out of 165\n",
      "68 out of 165\n",
      "69 out of 165\n",
      "70 out of 165\n",
      "71 out of 165\n",
      "72 out of 165\n",
      "73 out of 165\n",
      "74 out of 165\n",
      "75 out of 165\n",
      "76 out of 165\n",
      "77 out of 165\n",
      "78 out of 165\n",
      "79 out of 165\n",
      "80 out of 165\n",
      "81 out of 165\n",
      "82 out of 165\n",
      "83 out of 165\n",
      "84 out of 165\n",
      "85 out of 165\n",
      "86 out of 165\n",
      "87 out of 165\n",
      "88 out of 165\n",
      "89 out of 165\n",
      "90 out of 165\n",
      "91 out of 165\n",
      "92 out of 165\n",
      "93 out of 165\n",
      "94 out of 165\n",
      "95 out of 165\n",
      "96 out of 165\n",
      "97 out of 165\n",
      "98 out of 165\n",
      "99 out of 165\n",
      "100 out of 165\n",
      "101 out of 165\n",
      "102 out of 165\n",
      "103 out of 165\n",
      "104 out of 165\n",
      "105 out of 165\n",
      "106 out of 165\n",
      "107 out of 165\n",
      "108 out of 165\n",
      "109 out of 165\n",
      "110 out of 165\n",
      "111 out of 165\n",
      "112 out of 165\n",
      "113 out of 165\n",
      "114 out of 165\n",
      "115 out of 165\n",
      "116 out of 165\n",
      "117 out of 165\n",
      "118 out of 165\n",
      "119 out of 165\n",
      "120 out of 165\n",
      "121 out of 165\n",
      "122 out of 165\n",
      "123 out of 165\n",
      "124 out of 165\n",
      "125 out of 165\n",
      "126 out of 165\n",
      "127 out of 165\n",
      "128 out of 165\n",
      "129 out of 165\n",
      "130 out of 165\n",
      "131 out of 165\n",
      "132 out of 165\n",
      "133 out of 165\n",
      "134 out of 165\n",
      "135 out of 165\n",
      "136 out of 165\n",
      "137 out of 165\n",
      "138 out of 165\n",
      "139 out of 165\n",
      "140 out of 165\n",
      "141 out of 165\n",
      "142 out of 165\n",
      "143 out of 165\n",
      "144 out of 165\n",
      "145 out of 165\n",
      "146 out of 165\n",
      "147 out of 165\n",
      "148 out of 165\n",
      "149 out of 165\n",
      "150 out of 165\n",
      "151 out of 165\n",
      "152 out of 165\n",
      "153 out of 165\n",
      "154 out of 165\n",
      "155 out of 165\n",
      "156 out of 165\n",
      "157 out of 165\n",
      "158 out of 165\n",
      "159 out of 165\n",
      "160 out of 165\n",
      "161 out of 165\n",
      "162 out of 165\n",
      "163 out of 165\n",
      "164 out of 165\n",
      "165 out of 165\n"
     ]
    }
   ],
   "source": [
    "#Audio dad-child (Pittsburgh)\n",
    "#record-667269360.9571331.wav'\n",
    "\n",
    "#Audio ASU mom-child\n",
    "#filename = '../EMBRACE-data-analysis/audios/asu/par007_record-673758082.558921.wav'\n",
    "\n",
    "#filename = '../EMBRACE-data-analysis/audios/asu/par007_record-673758082.558921_reduced_noise.wav'\n",
    "#filename = '../EMBRACE-data-analysis/audios/asu/mom-child-62'\n",
    "\n",
    "#Audio dad-child (Pittsburgh)\n",
    "#filename='../EMBRACE-data-analysis/audios/record-667269360.9571331.wav'\n",
    "#filename='../EMBRACE-data-analysis/audios/record-667269360.9571331_reduced_noise.wav'\n",
    "\n",
    "#Audio mom-grandma-child (Pittsburgh)\n",
    "#filename = '../EMBRACE-data-analysis/audios/record-672279722.51811.wav'\n",
    "\n",
    "#ASU par001\n",
    "#filename = '../EMBRACE-data-analysis/audios/asu/par001-record-656468528.8997459_silence_removed.wav'\n",
    "#filename = '../EMBRACE-data-analysis/audios/asu/par001-record-656468528.8997459.wav'\n",
    "\n",
    "#ASU par010 (with Sindhu there) DO NOT USE\n",
    "#filename = '../EMBRACE-data-analysis/audios/asu/par010-record-691979477.209939.wav'\n",
    "\n",
    "#ASU par102\n",
    "#filename = \"../EMBRACE-data-analysis/audios/asu/par102-record-666060012.245397.wav\"\n",
    "\n",
    "#ASU par003\n",
    "#filename = \"../EMBRACE-data-analysis/audios/asu/par003-record-674009351.193422.wav\"\n",
    "\n",
    "#short test audio\n",
    "#filename='../EMBRACE-data-analysis/audios/two_speakers.wav'\n",
    "\n",
    "#Pitt 2023 study with families\n",
    "#Family 18\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_18/18_Chromebook Data/18_voice-recordings/voice-recording-1684538821337-1684538952706.mp3\"\n",
    "\n",
    "#Family 02\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_02/02_Chromebook Data/02_voice-recordings/voice-recording-1683119416725.mp3\"\n",
    "\n",
    "#Family 27\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_27/27_Chromebook Data/27_voice-recordings/voice-recording-1685319746913-1685319853260.mp3\"\n",
    "\n",
    "#Family 38\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_38/38_Chromebook Data/38_voice-recordings/voice-recording-1684368089828-1684368206019.mp3\"\n",
    "\n",
    "#Family 14\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_14/14_Chromebook Data/14_voice-recordings/voice-recording-1684963744854-1684963905574.mp3\"\n",
    "\n",
    "#Family 40\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_40/40_Chromebook Data/40_voice-recordings/voice-recording-1687288725889-1687288838114.mp3\"\n",
    "\n",
    "#Family 26\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_26/26_Chromebook Data/26_voice-recordings/voice-recording-1685893721966-1685893804426.mp3\"\n",
    "\n",
    "#Family 24\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_24/24_Chromebook Data/24_voice-recordings/voice-recording-1685132891234-1685132981986.mp3\"\n",
    "\n",
    "#Family 28\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_28/28_Chromebook Data/28_voice-recordings/voice-recording-1684283308048-1684283452364.mp3\"\n",
    "\n",
    "#Family 21\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_21/21_Chromebook Data/21_voice-recordings/voice-recording-1685314186787-1685314317009.mp3\"\n",
    "\n",
    "#Family 11\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_11/11_Chromebook Data/11_voice-recordings/voice-recording-1685581324665-1685581540964.mp3\"\n",
    "\n",
    "#Family 07\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_07/07_Chromebook Data/07_voice-recordings/voice-recording-1684176308802-1684176427677.mp3\"\n",
    "\n",
    "#Family 15\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_15/15_Chromebook Data/15_voice-recordings/voice-recording-1684537845698-1684537986048.mp3\"\n",
    "\n",
    "#Family 36\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_36/36_Chromebook Data/36_voice-recordings/voice-recording-1684531617245-1684531768249.mp3\"\n",
    "\n",
    "#Family 06\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_06/06_Chromebook Data/06_voice-recordings/voice-recording-1684463411814-1684463551576.mp3\"\n",
    "\n",
    "#Family 23\n",
    "#filename=\"../EMBRACE-data-analysis/data/summer23-pitt/Family_23/23_Chromebook Data/23_voice-recordings/voice-recording-1683462871149-1683462992344.mp3\"\n",
    "\n",
    "#Family 32\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_32/32_Chromebook Data/32_voice-recordings/voice-recording-1687372131141-1687372290025.mp3\"\n",
    "\n",
    "#Family 05\n",
    "#filename=\"../EMBRACE-data-analysis/data/summer23-pitt/Family_05/05_Chromebook Data/05_voice-recordings/voice-recording-1686071270169-1686071413625.mp3\"\n",
    "\n",
    "#Family 03\n",
    "#filename =\"../EMBRACE-data-analysis/data/summer23-pitt/Family_03/03_Chromebook Data/03_voice-recordings/voice-recording-1683505777195-1683505963551.mp3\"\n",
    "\n",
    "#Family 41\n",
    "#filename =\"../EMBRACE-data-analysis/data/summer23-pitt/Family_41/41_Chromebook Data/41_voice-recordings/voice-recording-1686527367557-1686527501435.mp3\"\n",
    "\n",
    "#Family 10\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_10/10_Chromebook Data/10_voice-recordings/voice-recording-1684374040208-1684374136892.mp3\"\n",
    "\n",
    "#Family 33\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_33/33_Chromebook Data/33_voice-recordings/voice-recording-1684015435229-1684015599799.mp3\"\n",
    "\n",
    "#Family 25\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_25/25_Chromebook Data/25_voice-recordings/voice-recording-1684369953635-1684370059814.mp3\"\n",
    "\n",
    "#Family 42\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_42/42_Chromebook Data/42_voice-recordings/voice-recording-1688168278100-1688168397606.mp3\"\n",
    "\n",
    "#Family 08\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_08/08_Chromebook Data/08_voice-recordings/voice-recording-1684200667651-1684200837711.mp3\"\n",
    "\n",
    "#Family 01\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_01/01_Chromebook Data/01_voice-recordings/voice-recording-1684287809686-1684287934521.mp3\"\n",
    "\n",
    "#Family 09\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_09/09_Chromebook Data/09_voice-recordings/voice-recording-1684283629157-1684283755416.mp3\"\n",
    "\n",
    "#Family 12\n",
    "#filename=\"../EMBRACE-data-analysis/data/summer23-pitt/Family_12/12_Chromebook Data/12_voice-recordings/voice-recording-1683728692360-1683728828299.mp3\"\n",
    "\n",
    "#Family 17\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_17/17_Chromebook Data/17_voice-recordings/voice-recording-1686352280180-1686352526753.mp3\"\n",
    "\n",
    "#Family 13\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_13/13_Chromebook Data/13_voice-recordings/voice-recording-1683932370969-1683932514346.mp3\"\n",
    "\n",
    "#Family 44\n",
    "filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_44/44_Chromebook Data/44_voice-recordings/voice-recording-1686179246263-1686179502991.mp3\"\n",
    "\n",
    "#Classify small chunks into the identity of the speaker\n",
    "try:\n",
    "    audio = AudioSegment.from_file(filename, \"mp3\")\n",
    "except:\n",
    "    audio = AudioSegment.from_file(filename, format=\"mp4\")\n",
    "\n",
    "voice_activity = get_voice_activity(filename,False,False)\n",
    "custom_size_voice_activity = custom_size_segments(voice_activity)\n",
    "\n",
    "#manual labeling of the voice segments\n",
    "#child=c\n",
    "#robot male english = rme\n",
    "#robot male spanish = rms\n",
    "#robot female english = rfe\n",
    "#robot female spanish = rfs\n",
    "#adult male = am\n",
    "#adult female = af\n",
    "#(if additional adults number them)\n",
    "#adult male 2 = am2\n",
    "#adult female 2 = af2 ...\n",
    "#if they are talking simultaneously = A&B\n",
    "#if they are talking separately but sequentially = A,B\n",
    "\n",
    "labeling_file_str = \"\"\n",
    "starting_index = int(input(\"Which index would you like to start from? (type 0 if from the beginning or >0 if you want to continue labeling):\"))\n",
    "for i in range (starting_index,len(custom_size_voice_activity)):\n",
    "    active_segment = custom_size_voice_activity[i]\n",
    "#for active_segment in custom_size_voice_activity:\n",
    "    play_audio_segment(audio,active_segment[0]*1000,active_segment[1]*1000)\n",
    "    label = input(\"Enter label for this audio segment: \")\n",
    "    if(label==\"end\"):#stop tagging\n",
    "        break\n",
    "    while(label==\"r\"):#if you want the audio chunk to be repeated\n",
    "        play_audio_segment(audio,active_segment[0]*1000,active_segment[1]*1000)\n",
    "        label = input(\"Enter label for this audio segment: \")\n",
    "        if(label==\"end\"):\n",
    "            break\n",
    "    label_line = str(i)+\" \"+str(active_segment)+\" \"+label\n",
    "    labeling_file_str = labeling_file_str + label_line + \"\\n\"\n",
    "    print(str(i)+\" out of \"+str(len(custom_size_voice_activity)-1))\n",
    "if(starting_index==0):\n",
    "    f = open(filename+\"_labeled_jordan.txt\", \"w\")\n",
    "    f.write(labeling_file_str)\n",
    "    f.close()\n",
    "elif(starting_index<len(custom_size_voice_activity)):\n",
    "    f = open(filename+\"_labeled_jordan.txt\", \"a\")\n",
    "    f.write(labeling_file_str)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def split(delimiters, string, maxsplit=0):\n",
    "    import re\n",
    "    regex_pattern = '|'.join(map(re.escape, delimiters))\n",
    "    return re.split(regex_pattern, string, maxsplit)\n",
    "\n",
    "#Interreliability assessment\n",
    "labeled_path =  \"../EMBRACE-data-analysis/data/labeled\"\n",
    "\n",
    "# list to store files\n",
    "labeled_files_list = []\n",
    "\n",
    "# Iterate directory\n",
    "for file_path in os.listdir(labeled_path):\n",
    "    # check if current file_path is a file\n",
    "    if os.path.isfile(os.path.join(labeled_path, file_path)):\n",
    "        # add filename to list\n",
    "        labeled_files_list.append(file_path)\n",
    "#print(res)\n",
    "\n",
    "analyzed_audios = []\n",
    "for labeled_file in labeled_files_list:\n",
    "    labeled_audio_name = \"\"\n",
    "    mp3_index = labeled_file.find(\".mp3\")\n",
    "    wav_index = labeled_file.find(\".wav\")\n",
    "    if(mp3_index!=-1):\n",
    "        labeled_audio_name = labeled_file[0:mp3_index]+\".mp3\"\n",
    "    else:\n",
    "        if(wav_index!=-1):\n",
    "            labeled_audio_name = labeled_file[0:wav_index]+\".wav\"\n",
    "    if(labeled_audio_name not in analyzed_audios):\n",
    "        print(labeled_audio_name)\n",
    "        analyzed_audios.append(labeled_audio_name)\n",
    "\n",
    "name_labeler_1 = \"jordan\"\n",
    "name_labeler_2 = \"danish\"\n",
    "\n",
    "labels_1 =[]\n",
    "labels_2 =[]\n",
    "\n",
    "#labels to say\n",
    "labels_1_child_nochild =[]\n",
    "labels_2_child_nochild =[]\n",
    "\n",
    "#labels to say if an audio had a single speaker or multiple ones\n",
    "labels_1_single_mult =[]\n",
    "labels_2_single_mult =[]\n",
    "\n",
    "#counting the number of non-coincidences\n",
    "non_coincidences_overall = 0\n",
    "\n",
    "#counting the number of total segments\n",
    "total_segments = 0\n",
    "\n",
    "#delimiters for multiple speakers\n",
    "delimiters = \",\",\"&\"\n",
    "\n",
    "for audio_name in analyzed_audios:\n",
    "    labeled_1= labeled_path+\"/\"+audio_name+\"_labeled_\"+name_labeler_1+\".txt\"\n",
    "    labeled_2= labeled_path+\"/\"+audio_name+\"_labeled_\"+name_labeler_2+\".txt\"\n",
    "    file_1 = open(labeled_1, \"r\")\n",
    "    file_2 = open(labeled_2, \"r\")\n",
    "    lines_1 = file_1.readlines()\n",
    "    lines_2 = file_2.readlines()\n",
    "    lines_1_len = len(lines_1)\n",
    "    lines_2_len = len(lines_2)\n",
    "    #print('Total Number of lines 1', lines_1_len)\n",
    "    #print('Total Number of lines 2', lines_2_len)\n",
    "\n",
    "    total_segments = total_segments + lines_1_len\n",
    "    if(lines_1_len==lines_2_len):\n",
    "        for i in range(0,lines_1_len):\n",
    "            line1=lines_1[i].strip()\n",
    "            line2=lines_2[i].strip()\n",
    "            label1 = line1[line1.rfind(\" \"):len(line1)]\n",
    "            ischild_1 = \"c\" in label1\n",
    "            issingle_1 = (\",\" in label1) or (\"&\" in label1)\n",
    "            label2 = line2[line2.rfind(\" \"):len(line2)]\n",
    "            ischild_2 = \"c\" in label2\n",
    "            issingle_2 = (\",\" in label2) or (\"&\" in label2)\n",
    "\n",
    "            if(\",\" in label1 or \"&\" in label1):\n",
    "                array_labels1 = split(delimiters,label1)\n",
    "                array_labels1.sort()\n",
    "                #print(array_labels1)\n",
    "                label1=' '.join(array_labels1)\n",
    "            if(\",\" in label2 or \"&\" in label2):\n",
    "                array_labels2 = split(delimiters,label2)\n",
    "                array_labels2.sort()\n",
    "                #print(array_labels2)\n",
    "                label2=' '.join(array_labels2)\n",
    "\n",
    "            if(label1!=label2):\n",
    "                print(\"Non coincidence in \"+audio_name)\n",
    "                print(label1)\n",
    "                print(label2)\n",
    "                non_coincidences_overall = non_coincidences_overall + 1\n",
    "\n",
    "            labels_1.append(label1)\n",
    "            labels_1_child_nochild.append(ischild_1)\n",
    "            labels_1_single_mult.append(issingle_1)\n",
    "\n",
    "            labels_2.append(label2)\n",
    "            labels_2_child_nochild.append(ischild_2)\n",
    "            labels_2_single_mult.append(issingle_2)\n",
    "\n",
    "    file_1.close()\n",
    "    file_2.close()\n",
    "#Total labeled segments\n",
    "print(\"Total labeled segments: \"+str(total_segments))\n",
    "\n",
    "print(\"Number of raw non-coincidences: \"+str(non_coincidences_overall))\n",
    "\n",
    "#Calculates Cohen's kappa\n",
    "cohen_kappa = cohen_kappa_score(labels_1,labels_2)\n",
    "print(\"Cohen's kappa: \"+str(cohen_kappa))\n",
    "\n",
    "#Calculates Cohen's kappa (simplified -> child or no child)\n",
    "cohen_kappa_child = cohen_kappa_score(labels_1_child_nochild,labels_2_child_nochild)\n",
    "print(\"Cohen's kappa simplified (child vs no child): \"+str(cohen_kappa_child))\n",
    "\n",
    "#Calculates Cohen's kappa (simplified -> single vs multiple speakers)\n",
    "cohen_kappa_single = cohen_kappa_score(labels_1_single_mult,labels_2_single_mult)\n",
    "print(\"Cohen's kappa simplified (single vs multiple speakers): \"+str(cohen_kappa_single))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
