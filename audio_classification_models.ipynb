{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "#Danish you can comment this one\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "#import set of functions I made for the automatic analysis of the audios\n",
    "import sys\n",
    "\n",
    "#here the path needs to be changed to your own local path\n",
    "sys.path.insert(1, '/Users/jab464/Documents/Github/EMBRACE-data-analysis/')\n",
    "from audio_analysis_functions import *\n",
    "\n",
    "#Automatic transcription modules needed\n",
    "import whisper\n",
    "from whisper.utils import get_writer\n",
    "\n",
    "#import needed to create a\n",
    "import os\n",
    "\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../EMBRACE-data-analysis/data/summer23-pitt/Family_05/05_Chromebook Data/05_voice-recordings/voice-recording-1686071270169-1686071413625\n",
      "voice-recording-1686071270169-1686071413625\n",
      "../EMBRACE-data-analysis/data/summer23-pitt/Family_05/05_Chromebook Data/05_voice-recordings\n"
     ]
    }
   ],
   "source": [
    "#Summer 23 data sample\n",
    "\n",
    "#Family 03 - mixture of english and spanish (mostly english from the kids side)\n",
    "#filename = \"../EMBRACE-data-analysis/data/summer23-pitt/Family_03/03_Chromebook Data/03_voice-recordings/voice-recording-1683505777195-1683505963551.mp3\"\n",
    "\n",
    "#Family 05\n",
    "filename=\"../EMBRACE-data-analysis/data/summer23-pitt/Family_05/05_Chromebook Data/05_voice-recordings/voice-recording-1686071270169-1686071413625.mp3\"\n",
    "\n",
    "#Family 41 - all spanish\n",
    "#filename =\"../EMBRACE-data-analysis/data/summer23-pitt/Family_41/41_Chromebook Data/41_voice-recordings/voice-recording-1686527367557-1686527501435.mp3\"\n",
    "\n",
    "filename_no_mp3 = filename[0:len(filename)-4]\n",
    "\n",
    "#only the name of the file withouth the whole path\n",
    "filename_no_mp3_no_folder = filename_no_mp3[filename_no_mp3.rfind('/')+1:len(filename_no_mp3)]\n",
    "\n",
    "root_folder = filename_no_mp3[0:filename_no_mp3.rfind('/')]\n",
    "\n",
    "print(filename_no_mp3)\n",
    "print(filename_no_mp3_no_folder)\n",
    "print(root_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "503 Server Error: Service Temporarily Unavailable for url: https://huggingface.co/pyannote/voice-activity-detection/resolve/main/config.yaml",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/pyannote/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:264\u001B[0m, in \u001B[0;36mhf_raise_for_status\u001B[0;34m(response, endpoint_name)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 264\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/miniconda3/envs/pyannote/lib/python3.8/site-packages/requests/models.py:1021\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1020\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n\u001B[0;32m-> 1021\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[0;31mHTTPError\u001B[0m: 503 Server Error: Service Temporarily Unavailable for url: https://huggingface.co/pyannote/voice-activity-detection/resolve/main/config.yaml",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mHfHubHTTPError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#extract only the active voice audio\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m pipeline_act_detection \u001B[38;5;241m=\u001B[39m \u001B[43mPipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpyannote/voice-activity-detection\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhf_DHDEpmiDLkwrxpSGIdivCjCbkbmqEwdhwx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#extracted audio\u001B[39;00m\n\u001B[1;32m      5\u001B[0m output \u001B[38;5;241m=\u001B[39m pipeline_act_detection(filename)\n",
      "File \u001B[0;32m~/miniconda3/envs/pyannote/lib/python3.8/site-packages/pyannote/audio/core/pipeline.py:85\u001B[0m, in \u001B[0;36mPipeline.from_pretrained\u001B[0;34m(cls, checkpoint_path, hparams_file, use_auth_token, cache_dir)\u001B[0m\n\u001B[1;32m     82\u001B[0m                 revision \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     84\u001B[0m             \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 85\u001B[0m                 config_yml \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     87\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mPIPELINE_PARAMS_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     89\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     90\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mlibrary_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpyannote\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     91\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mlibrary_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m__version__\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;66;43;03m# force_download=False,\u001B[39;49;00m\n\u001B[1;32m     94\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;66;43;03m# proxies=None,\u001B[39;49;00m\n\u001B[1;32m     95\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;66;43;03m# etag_timeout=10,\u001B[39;49;00m\n\u001B[1;32m     96\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;66;43;03m# resume_download=False,\u001B[39;49;00m\n\u001B[1;32m     97\u001B[0m \u001B[43m                    \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;66;43;03m# local_files_only=False,\u001B[39;49;00m\n\u001B[1;32m     99\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;66;43;03m# legacy_cache_layout=False,\u001B[39;49;00m\n\u001B[1;32m    100\u001B[0m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    102\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m RepositoryNotFoundError:\n\u001B[1;32m    103\u001B[0m                 \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    104\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;124mCould not download \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m pipeline.\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;124mvisit https://hf.co/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to accept the user conditions.\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m    115\u001B[0m                 )\n",
      "File \u001B[0;32m~/miniconda3/envs/pyannote/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:124\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    120\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(\n\u001B[1;32m    121\u001B[0m         fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs\n\u001B[1;32m    122\u001B[0m     )\n\u001B[0;32m--> 124\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/pyannote/lib/python3.8/site-packages/huggingface_hub/file_download.py:1105\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001B[0m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1104\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1105\u001B[0m         metadata \u001B[38;5;241m=\u001B[39m \u001B[43mget_hf_file_metadata\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1106\u001B[0m \u001B[43m            \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1107\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1108\u001B[0m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1109\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1110\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m EntryNotFoundError \u001B[38;5;28;01mas\u001B[39;00m http_error:\n\u001B[1;32m   1112\u001B[0m         \u001B[38;5;66;03m# Cache the non-existence of the file and raise\u001B[39;00m\n\u001B[1;32m   1113\u001B[0m         commit_hash \u001B[38;5;241m=\u001B[39m http_error\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m   1114\u001B[0m             HUGGINGFACE_HEADER_X_REPO_COMMIT\n\u001B[1;32m   1115\u001B[0m         )\n",
      "File \u001B[0;32m~/miniconda3/envs/pyannote/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:124\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    120\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(\n\u001B[1;32m    121\u001B[0m         fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs\n\u001B[1;32m    122\u001B[0m     )\n\u001B[0;32m--> 124\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/pyannote/lib/python3.8/site-packages/huggingface_hub/file_download.py:1440\u001B[0m, in \u001B[0;36mget_hf_file_metadata\u001B[0;34m(url, token, proxies, timeout)\u001B[0m\n\u001B[1;32m   1430\u001B[0m \u001B[38;5;66;03m# Retrieve metadata\u001B[39;00m\n\u001B[1;32m   1431\u001B[0m r \u001B[38;5;241m=\u001B[39m _request_wrapper(\n\u001B[1;32m   1432\u001B[0m     method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHEAD\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1433\u001B[0m     url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1438\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[1;32m   1439\u001B[0m )\n\u001B[0;32m-> 1440\u001B[0m \u001B[43mhf_raise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1442\u001B[0m \u001B[38;5;66;03m# Return\u001B[39;00m\n\u001B[1;32m   1443\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m HfFileMetadata(\n\u001B[1;32m   1444\u001B[0m     commit_hash\u001B[38;5;241m=\u001B[39mr\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(HUGGINGFACE_HEADER_X_REPO_COMMIT),\n\u001B[1;32m   1445\u001B[0m     etag\u001B[38;5;241m=\u001B[39m_normalize_etag(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1458\u001B[0m     ),\n\u001B[1;32m   1459\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/pyannote/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:318\u001B[0m, in \u001B[0;36mhf_raise_for_status\u001B[0;34m(response, endpoint_name)\u001B[0m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m BadRequestError(message, response\u001B[38;5;241m=\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001B[39;00m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;66;03m# as well (request id and/or server error message)\u001B[39;00m\n\u001B[0;32m--> 318\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m HfHubHTTPError(\u001B[38;5;28mstr\u001B[39m(e), response\u001B[38;5;241m=\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mHfHubHTTPError\u001B[0m: 503 Server Error: Service Temporarily Unavailable for url: https://huggingface.co/pyannote/voice-activity-detection/resolve/main/config.yaml"
     ]
    }
   ],
   "source": [
    "#extract only the active voice audio\n",
    "pipeline_act_detection = Pipeline.from_pretrained(\"pyannote/voice-activity-detection\",\n",
    "                                        use_auth_token=\"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\")\n",
    "#extracted audio\n",
    "output = pipeline_act_detection(filename)\n",
    "\n",
    "# Specify the name of the new folder\n",
    "folder_path = filename_no_mp3+\"_no_silences\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"The path '{folder_path}' exists.\")\n",
    "else:\n",
    "    print(f\"The path '{folder_path}' does not exist.\")\n",
    "    # Create the new folder\n",
    "    os.mkdir(folder_path)\n",
    "\n",
    "try:\n",
    "    audio = AudioSegment.from_file(filename, \"mp3\")\n",
    "except:\n",
    "    audio = AudioSegment.from_file(filename, format=\"mp4\")\n",
    "\n",
    "counter = 0\n",
    "for speech in output.get_timeline().support():\n",
    "    # Extract the chunk\n",
    "    start_time = speech.start\n",
    "    end_time = speech.end\n",
    "    chunk = audio[start_time*1000:end_time*1000]\n",
    "    # Export the extracted chunk to a new audio file\n",
    "    chunk.export(folder_path+\"/\"+filename_no_mp3_no_folder+\"_\"+str(counter)+\".mp3\", format=\"mp3\")\n",
    "    counter=counter+1\n",
    "\n",
    "# List of audio file paths to concatenate\n",
    "audio_files = []\n",
    "\n",
    "#fill audio files list with all the active voice chunks generated in the last for loop\n",
    "for i in range (0,counter):\n",
    "    audio_files.append(folder_path+\"/\"+filename_no_mp3_no_folder+\"_\"+str(i)+\".mp3\")\n",
    "\n",
    "# Initialize an empty AudioSegment object to hold the concatenated audio\n",
    "concatenated_audio = AudioSegment.empty()\n",
    "\n",
    "# Iterate through each audio file\n",
    "for file in audio_files:\n",
    "    # Load the audio file\n",
    "    curr_audio = AudioSegment.from_file(file)\n",
    "\n",
    "    # Append the loaded audio to the concatenated audio\n",
    "    concatenated_audio += curr_audio\n",
    "\n",
    "# Export the concatenated audio withouth silences to a new file\n",
    "concatenated_audio.export(folder_path+\"/\"+filename_no_mp3_no_folder+\"_no_silences.mp3\", format=\"mp3\")\n",
    "\n",
    "#Gets the file without silences (yes again) but in a different format\n",
    "voice_activity = get_voice_activity(filename,False,False,False)\n",
    "#it segments the data in 1 second segments\n",
    "custom_size_voice_activity = custom_size_segments(voice_activity)\n",
    "\n",
    "#Sound with no silences\n",
    "snd = parselmouth.Sound(folder_path+\"/\"+filename_no_mp3_no_folder+\"_no_silences.mp3\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to analyze a segment and extract MFCC and pitch values\n",
    "def analyze_segment(snd, start_time, end_time):\n",
    "    # Extract a part of the sound between start_time and end_time\n",
    "    segment = snd.extract_part(from_time=start_time, to_time=end_time, preserve_times=True)\n",
    "    # Extract pitch for the segment\n",
    "    pitch = segment.to_pitch()\n",
    "    pitch_values = pitch.selected_array['frequency']\n",
    "    # Replace unvoiced (0) with NaN\n",
    "    pitch_values[pitch_values == 0] = np.nan\n",
    "    # Extract MFCC for the segment\n",
    "    mfcc = segment.to_mfcc()\n",
    "    mfcc_values = mfcc.to_array()\n",
    "    return pitch_values, mfcc_values\n",
    "\n",
    "# Initialize lists to store data\n",
    "data = []\n",
    "max_pitch_length = 97  # Maximum number of pitch values per segment\n",
    "num_mfcc = 13  # Assuming 13 MFCC coefficients for simplicity\n",
    "# Example labels (replace this with your actual labeling logic)\n",
    "labels = [f\"Label_{i+1}\" for i in range(len(custom_size_voice_activity))]\n",
    "for i, segment in enumerate(custom_size_voice_activity):\n",
    "    start, end = segment\n",
    "    pitch_values, mfcc_values = analyze_segment(snd, start, end)\n",
    "    # Calculate the average pitch, excluding NaN values\n",
    "    avg_pitch = np.nanmean(pitch_values)\n",
    "    # getting the avg mfcc\n",
    "    mfcc_avg = np.mean(mfcc_values, axis=1)\n",
    "    # Combine all the data for this segment into one list\n",
    "    segment_data = list(pitch_values) + [avg_pitch] + list(mfcc_avg) + [labels[i]]\n",
    "    # Append the segment's data to the overall data list\n",
    "    data.append(segment_data)\n",
    "# Column names: 97 pitch columns, 1 avg pitch column, MFCC columns, and 1 label column\n",
    "column_names = [f'Pitch_{i+1}' for i in range(max_pitch_length)] + ['Avg_Pitch'] + [f'MFCC_{j+1}' for j in range(num_mfcc)] + ['Label']\n",
    "# Create a DataFrame from the data list\n",
    "df = pd.DataFrame(data, columns=column_names)\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('audio_features_with_labels.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Load the training files\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
